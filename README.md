---

# IMDB Sentiment Analysis with LSTM

This project implements a sentiment analysis model using a **Long Short-Term Memory (LSTM)** network. It is designed to classify movie reviews from a local CSV file as either **Positive** or **Negative**.

---

## Project Structure

* **`IMDB_Dataset.csv`**: The source data containing reviews and labels (positive/negative).
* **`training.py`**: The training script that handles data cleaning, tokenization, model building, and asset exporting.
* **`rate_review.py`**: A command-line script to load the trained model and predict sentiment for a single review.
* **`imdb_lstm_model.h5`**: The exported Keras model file generated by the training script.
* **`tokenizer.pickle`**: The exported word-index mapping used to ensure consistent preprocessing during inference.

---

## Requirements

Ensure you have the following Python libraries installed:

```bash
pip install pandas numpy tensorflow scikit-learn

```

---

## 1. Training and Exporting

The `training.py` script requires you to pass the path of your dataset file as a command-line argument. It performs full preprocessing and trains the neural network.

### Execution

To start the training and export the model/tokenizer, run:

```bash
python training.py "IMDB_Dataset.csv"

```

### What the Training Script Does:

* **Cleaning**: Removes `<br />` HTML tags and converts all text to lowercase for better feature extraction.
* **Tokenization**: Indexes the top 10,000 most frequent words.
* **Padding**: Forces all review sequences to a fixed length of 200 words.
* **Model Architecture**: Uses an **Embedding** layer, a 128-unit **LSTM** layer with **Dropout** (0.2), and a **Dense** output layer with a **Sigmoid** activation.
* **Optimization**: Employs the `adam` optimizer and `binary_crossentropy` loss function.
* **Early Stopping**: Monitors `val_loss` and stops training automatically if accuracy plateaus to prevent overfitting.

---

## 2. Running Inference (Rate a Review)

Once you have generated `imdb_lstm_model.h5` and `tokenizer.pickle`, you can use the `rate_review.py` script to classify any text.

**Command Format:**

```bash
python rate_review.py "Your movie review here"

```

### Example:

```bash
python rate_review.py "The cinematography was stunning and the plot was deeply moving."

```

### Example Output:

```text
Review: The cinematography was stunning and the plot was deeply moving.
Sentiment: POSITIVE (Confidence: 0.9886)

```

---

## How it Works

1. **Preprocessing**: Input text is cleaned and lowercased to match training data.
2. **Conversion**: The saved `tokenizer.pickle` converts the words into the specific integer sequences the model understands.
3. **LSTM Processing**: The LSTM's internal gates (Forget, Input, and Output) process the word sequence to understand long-term context.
4. **Probability**: The final layer outputs a value between 0 and 1; values > 0.5 are classified as **Positive**.

---

## Troubleshooting

* **Missing Argument**: If you run `python training.py` without a file path, it will display a usage reminder: `Usage: python train.py 'dataset file path'`.
* **Asset Loading**: Ensure `rate_review.py` is looking for the exact filenames `imdb_lstm_model.h5` and `tokenizer.pickle`.
* **Metrics Warning**: You may see a warning about `compile_metrics` being empty when loading the model for inference; this is standard and does not affect prediction performance.

---
